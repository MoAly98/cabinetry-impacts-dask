{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Distributed ranking plot computations with new impacts methods</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of demo day #8 (04.04.2025), this demonstration requires a custom branch of `cabinetry`, which can be pulled with \n",
    "```\n",
    "pip install git+https://github.com/MoAly98/cabinetry.git@maly-issue-442\n",
    "```\n",
    "\n",
    "and your environment should force install the `main` branch of `pyhf`\n",
    "```\n",
    "pip install git+https://github.com/scikit-hep/pyhf.git@main\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates the distribution of ranking computation for a larger and more complex model extracted from `hepdata`. We first need to download the workspace from `hepdata`. We will follow a measurement of the single top-quark production cross-section in the s-channel, [published on `HEPData`](https://www.hepdata.net/record/resource/3386157?landing_page=true). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://www.hepdata.net/record/resource/3386157?view=false\"\n",
    "urllib.request.urlretrieve(url, \"complex_workspace.json\")\n",
    "\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\"> The new impacts methods</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `pyhf` workspace and review the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import shutil\n",
    "import pathlib\n",
    "import json\n",
    "\n",
    "import pyhf\n",
    "import cabinetry\n",
    "from cabinetry.fit import utils as fit_utils\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s - %(message)s\")\n",
    "logging.getLogger(\"cabinetry\").setLevel(logging.INFO)\n",
    "\n",
    "# Get the pyhf workspace from the model specs\n",
    "file_path = pathlib.Path(\"complex_workspace.json\")\n",
    "ws = json.loads(file_path.read_text())\n",
    "spec = pyhf.Workspace(ws)\n",
    "# Model and data\n",
    "model, data = cabinetry.model_utils.model_and_data(spec)\n",
    "print(f\"  channels: {model.config.channels}\")\n",
    "print(f\"     nbins: {model.config.channel_nbins}\")\n",
    "print(f\"   samples  [{len(model.config.samples)}]: {model.config.samples}\")\n",
    "print(f\" modifiers  [{len(model.config.modifiers)}]: {model.config.modifiers}\")\n",
    "print(f\"parameters  [{len(model.config.parameters)}]: {model.config.parameters}\")\n",
    "# List of parameter names\n",
    "parameters_list = model.config.par_names\n",
    "model_spec = model.spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabinetry.visualize.modifier_grid(model, figure_folder=\"complex_example/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the nominal fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_results = cabinetry.fit.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the model and data look correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the pre-fit model prediction and data\n",
    "prediction_prefit = cabinetry.model_utils.prediction(model)\n",
    "cabinetry.visualize.data_mc(prediction_prefit, data, figure_folder=\"complex_example/data_mc/\")\n",
    "\n",
    "# visualize the post-fit model prediction and data\n",
    "prediction_postfit = cabinetry.model_utils.prediction(model, fit_results=fit_results)\n",
    "cabinetry.visualize.data_mc(prediction_postfit, data, figure_folder=\"complex_example/data_mc/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what the nuisance parameter pulls look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabinetry.visualize.pulls(\n",
    "    fit_results, close_figure=True, save_figure=True, figure_folder=\"complex_example/pulls/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to run our ranking computations, and we have a choice of which method to use via the `impacts_method` argument in `cabinetry.fit.ranking`. Since we already ran the nominal fit, we can get the impacts with the covariance method instantly (for free)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logging.getLogger(\"cabinetry\").setLevel(logging.WARNING)\n",
    "# Run ranking with the covariance method\n",
    "ranking_results = cabinetry.fit.ranking(model, data, fit_results=fit_results, impacts_method=\"covariance\")\n",
    "cabinetry.visualize.ranking(ranking_results, close_figure=True, save_figure=True, figure_folder=\"complex_example/serial_rankings/\", max_pars=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes 20 seconds to run the nominal fit on an Apple M1 pro chip. For this model, a simple calculation tells us we need (at least) 2 hours to run the ranking with auxiliary data shifting and 4 hours to run the NP-shifting procedure. On `coffea-casa` images in Nebraska, it takes 180-200s to run the nominal fit. This would be 20-40 hours of run-time to finish the ranking computations with methods involving alternative fits.  So, it will make a huge difference to distribute this workload with `dask`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Distributed ranking computation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking is very computationally intensive in the NP-shifting and Auxiliary data-shifting methods. For this simple configuration, we don't feel it, but for larger models (e.g. 100 of parameters), the single-fit time increases, the number of fits required explodes, a ranking can take days to run sequentially.\n",
    "\n",
    "Current `cabinetry` implementation of the ranking function does not allow for any form of parallelisation without the user having to re-write elements of the function themselves.\n",
    "In this next part of the notebook, we demonstrate that there is now: \n",
    "- an infrastructure for the user to parallelise calls to the ranking function (4 fits at a time (NP) or 2 fits at a time (AUX))\n",
    "- an API to get a maximal distribution of individual ranking fits on a cluster via a `dask` client\n",
    "\n",
    "To run this part, `dask.distributed` is needed in the environment. You should run\n",
    "```\n",
    "pip install dask[distributed]\n",
    "``` \n",
    "\n",
    "Note that, in production, `dask` will be an optional dependency in `cabinetry`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:green;\"> Set up dask client </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from dask.distributed import Client, LocalCluster, PipInstall\n",
    "import cabinetry\n",
    "import pyhf\n",
    "\n",
    "COFFEA_CASA = True\n",
    "\n",
    "def get_client(n_workers=4):\n",
    "    if not COFFEA_CASA:\n",
    "        cluster = LocalCluster(n_workers=n_workers, processes=True, threads_per_worker=1)\n",
    "        client = Client(cluster)\n",
    "        print(f\"Dask dashboard: {cluster.dashboard_link}\")\n",
    "    else:\n",
    "        dependencies = [\n",
    "            \"git+https://github.com/MoAly98/cabinetry.git@maly-issue-442\",\n",
    "            \"git+https://github.com/scikit-hep/pyhf.git@main\",\n",
    "        ]\n",
    "        client = Client(\"tls://localhost:8786\")\n",
    "        client.register_plugin(PipInstall(packages=dependencies))\n",
    "        cluster = None  # no local cluster in this mode\n",
    "    return cluster, client\n",
    "\n",
    "def close_client(cluster, client):\n",
    "    if client:\n",
    "        client.close()\n",
    "    if cluster:\n",
    "        cluster.close()\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:green;\"> Parallelising ranking calls </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranking function now accepts a list of parameters for which the ranking should be computed. This option can be used to call the ranking function for one parameter at-a-time, and evaluate them in parallel on a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_fit_results(fit_results):\n",
    "    return {\n",
    "        \"bestfit\": fit_results.bestfit.tolist(),\n",
    "        \"uncertainty\": fit_results.uncertainty.tolist(),\n",
    "        \"labels\": list(fit_results.labels),\n",
    "        \"corr_mat\": fit_results.corr_mat.tolist(),\n",
    "        \"best_twice_nll\": float(fit_results.best_twice_nll),\n",
    "    }\n",
    "\n",
    "def run_dask(func, cluster, client, model_spec, data, fit_results, parameters_list):\n",
    "    fit_results_serialisable = serialize_fit_results(fit_results)\n",
    "    try:\n",
    "        futures = [\n",
    "            client.submit(func, param, model_spec, data, fit_results_serialisable)\n",
    "            for param in parameters_list\n",
    "        ]\n",
    "        return client.gather(futures)\n",
    "    except (KeyboardInterrupt, Exception) as e:\n",
    "        close_client(cluster, client)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function that returns the workload to be distributed\n",
    "# calls to this function are collected then distributed to the workers\n",
    "# the use of model spec and a fit results dict is to avoid pickling the model and fit results\n",
    "# which are not serliasable objects --> is there a better way?\n",
    "def get_ranking_function(param, model_spec, data, fit_results_serialisable, method=\"auxdata_shift\"):\n",
    "    fit_results_int = cabinetry.model_utils.FitResults(**fit_results_serialisable)\n",
    "    model_int = pyhf.Model(model_spec)\n",
    "    return cabinetry.fit.ranking(\n",
    "        model_int, data,\n",
    "        fit_results=fit_results_int,\n",
    "        impacts_method=method,\n",
    "        parameters_list=[param],\n",
    "        poi_name=\"mu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and run\n",
    "cluster, client = get_client(n_workers=4)\n",
    "\n",
    "start = time.time()\n",
    "try:\n",
    "    individual_ranking_results = run_dask(\n",
    "        get_ranking_function,\n",
    "        cluster,\n",
    "        client,\n",
    "        model_spec,\n",
    "        data,\n",
    "        fit_results,\n",
    "        parameters_list,\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    n_workers = len(client.scheduler_info()['workers'])\n",
    "    print(f\"Elapsed for {n_workers} workers: {elapsed:.2f} seconds\")\n",
    "finally:\n",
    "    cluster, client = close_client(cluster, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we  have the results from individual ranking calls, we need to combine them and plot! We implemented a utility to allow a user to do this combination quickly and pass the result to plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_results = fit_utils.collect_ranking_results(individual_ranking_results)\n",
    "cabinetry.visualize.ranking(\n",
    "    ranking_results, close_figure=True, save_figure=True, figure_folder=\"complex_example/dask_rankings/\", max_pars=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:green;\"> Parallelising fit calls </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can instead choose to let cabinetry handle the parallelisation for them by passing a dask client to the ranking funciton call. Behind the scenes, cabinetry will collect individual calls to the **fit** function, and then submit them to the cluster through the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster, client = get_client(n_workers=4)\n",
    "\n",
    "start = time.time()\n",
    "try:\n",
    "    ranking_result_auxdata_shift = cabinetry.fit.ranking(\n",
    "        model,\n",
    "        data,\n",
    "        fit_results=fit_results,\n",
    "        impacts_method=\"auxdata_shift\",\n",
    "        parameters_list=parameters_list,\n",
    "        poi_name=\"mu\",\n",
    "        client=client\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    n_workers = len(client.scheduler_info()['workers'])\n",
    "    print(f\"Elapsed for {n_workers} workers: {elapsed:.2f} seconds\")\n",
    "finally:\n",
    "    cluster, client = close_client(cluster, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabinetry.visualize.ranking(\n",
    "    ranking_result_auxdata_shift, close_figure=True, save_figure=True, figure_folder=\"complex_example/dask_rankings_by_fit/\", max_pars=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
