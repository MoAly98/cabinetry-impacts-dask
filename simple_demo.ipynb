{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Distributed ranking plot computations with new impacts methods</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of demo day #8 (04.04.2025), this demonstration requires a custom branch of `cabinetry`, which can be pulled with \n",
    "```\n",
    "pip install git+https://github.com/MoAly98/cabinetry.git@maly-issue-442\n",
    "```\n",
    "\n",
    "and your environment should force install the `main` branch of `pyhf`\n",
    "```\n",
    "pip install git+https://github.com/scikit-hep/pyhf.git@main\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create N-tuples to use for this example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python create_ntuples.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\"> The new impacts methods</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the cabinetry config and review the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import shutil\n",
    "\n",
    "import cabinetry\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s - %(message)s\")\n",
    "logging.getLogger(\"cabinetry\").setLevel(logging.INFO)\n",
    "import pyhf\n",
    "\n",
    "\n",
    "shutil.rmtree(\"histograms\", ignore_errors=True)\n",
    "\n",
    "# import example config file\n",
    "config = cabinetry.configuration.load(\"config_example.yml\")\n",
    "cabinetry.configuration.print_overview(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the required template histograms and run post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create template histograms\n",
    "cabinetry.templates.build(config)\n",
    "\n",
    "# perform histogram post-processing\n",
    "cabinetry.templates.postprocess(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create workspace, build model and run fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a workspace\n",
    "ws = cabinetry.workspace.build(config)\n",
    "# produce model and extract data\n",
    "model, data = cabinetry.model_utils.model_and_data(ws)\n",
    "parameters_list = model.config.par_names\n",
    "model_spec = model.spec\n",
    "# run the fit\n",
    "fit_results = cabinetry.fit.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the fit model looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the pre-fit model prediction and data\n",
    "prediction_prefit = cabinetry.model_utils.prediction(model)\n",
    "cabinetry.visualize.data_mc(prediction_prefit, data, config=config, figure_folder=\"simple_example/data_mc/\")\n",
    "\n",
    "# visualize the post-fit model prediction and data\n",
    "prediction_postfit = cabinetry.model_utils.prediction(model, fit_results=fit_results)\n",
    "cabinetry.visualize.data_mc(prediction_postfit, data, config=config, figure_folder=\"simple_example/data_mc/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what the nuisance parameter pulls look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabinetry.visualize.pulls(\n",
    "    fit_results, close_figure=True, save_figure=True, figure_folder=\"simple_example/pulls/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to run our ranking computations, and we have a choice of which method to use via the `impacts_method` argument in `cabinetry.fit.ranking`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"cabinetry\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run ranking with the NP-shifting method\n",
    "ranking_results = cabinetry.fit.ranking(model, data, fit_results=fit_results, impacts_method=\"np_shift\")\n",
    "cabinetry.visualize.ranking(ranking_results, close_figure=True, save_figure=True, figure_folder=\"simple_example/serial_rankings/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run ranking with covariance-based method: this is the default method\n",
    "ranking_results = cabinetry.fit.ranking(model, data, fit_results=fit_results, impacts_method=\"covariance\")\n",
    "cabinetry.visualize.ranking(ranking_results, close_figure=True, save_figure=True, figure_folder=\"simple_example/serial_rankings/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run ranking with covariance-based method: this is the default method\n",
    "ranking_results = cabinetry.fit.ranking(model, data, fit_results=fit_results, impacts_method=\"auxdata_shift\")\n",
    "cabinetry.visualize.ranking(ranking_results, close_figure=True, save_figure=True, figure_folder=\"simple_example/serial_rankings/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:green;\">Distributed ranking computation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking is very computationally intensive in the NP-shifting and Auxiliary data-shifting methods. For this simple configuration, we don't feel it, but for larger models (e.g. 100 of parameters), the single-fit time increases, the number of fits required explodes, a ranking can take days to run sequentially.\n",
    "\n",
    "Current `cabinetry` implementation of the ranking function does not allow for any form of parallelisation without the user having to re-write elements of the function themselves.\n",
    "In this next part of the notebook, we demonstrate that there is now: \n",
    "- an infrastructure for the user to parallelise calls to the ranking function (4 fits at a time (NP) or 2 fits at a time (AUX))\n",
    "- an API to get a maximal distribution of individual ranking fits on a cluster via a `dask` client\n",
    "\n",
    "To run this part, `dask.distributed` is needed in the environment. You should run\n",
    "```\n",
    "pip install dask[distributed]\n",
    "``` \n",
    "\n",
    "Note that, in production, `dask` will be an optional dependency in `cabinetry`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:green;\"> Set up dask client </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from dask.distributed import Client, LocalCluster, PipInstall\n",
    "\n",
    "COFFEA_CASA = True\n",
    "\n",
    "def get_client(n_workers=4):\n",
    "    if not COFFEA_CASA:\n",
    "        cluster = LocalCluster(n_workers=n_workers, processes=True, threads_per_worker=1)\n",
    "        client = Client(cluster)\n",
    "        print(f\"Dask dashboard: {cluster.dashboard_link}\")\n",
    "    else:\n",
    "        dependencies = [\n",
    "            \"git+https://github.com/MoAly98/cabinetry.git@maly-issue-442\",\n",
    "            \"git+https://github.com/scikit-hep/pyhf.git@main\",\n",
    "        ]\n",
    "        client = Client(\"tls://localhost:8786\")\n",
    "        client.register_plugin(PipInstall(packages=dependencies))\n",
    "        cluster = None  # no local cluster in this mode\n",
    "    return cluster, client\n",
    "\n",
    "def close_client(cluster, client):\n",
    "    if client:\n",
    "        client.close()\n",
    "    if cluster:\n",
    "        cluster.close()\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:green;\"> Parallelising ranking calls </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranking function now accepts a list of parameters for which the ranking should be computed. This option can be used to call the ranking function for one parameter at-a-time, and evaluate them in parallel on a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_fit_results(fit_results):\n",
    "    return {\n",
    "        \"bestfit\": fit_results.bestfit.tolist(),\n",
    "        \"uncertainty\": fit_results.uncertainty.tolist(),\n",
    "        \"labels\": list(fit_results.labels),\n",
    "        \"corr_mat\": fit_results.corr_mat.tolist(),\n",
    "        \"best_twice_nll\": float(fit_results.best_twice_nll),\n",
    "    }\n",
    "\n",
    "def run_dask(func, cluster, client, model_spec, data, fit_results, parameters_list):\n",
    "    fit_results_serialisable = serialize_fit_results(fit_results)\n",
    "    try:\n",
    "        futures = [\n",
    "            client.submit(func, param, model_spec, data, fit_results_serialisable)\n",
    "            for param in parameters_list\n",
    "        ]\n",
    "        return client.gather(futures)\n",
    "    except (KeyboardInterrupt, Exception) as e:\n",
    "        close_client(cluster, client)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the function that returns the workload to be distributed\n",
    "# calls to this function are collected then distributed to the workers\n",
    "# the use of model spec and a fit results dict is to avoid pickling the model and fit results\n",
    "# which are not serliasable objects --> is there a better way?\n",
    "def get_ranking_function(param, model_spec, data, fit_results_serialisable, method=\"auxdata_shift\"):\n",
    "    fit_results_int = cabinetry.model_utils.FitResults(**fit_results_serialisable)\n",
    "    model_int = pyhf.Model(model_spec)\n",
    "    return cabinetry.fit.ranking(\n",
    "        model_int, data,\n",
    "        fit_results=fit_results_int,\n",
    "        impacts_method=method,\n",
    "        parameters_list=[param],\n",
    "        poi_name=\"Signal_norm\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and run\n",
    "test_n_workers = range(1,5,1) if not COFFEA_CASA else [-1]\n",
    "for n_workers in test_n_workers:\n",
    "    cluster, client = get_client(n_workers=n_workers)\n",
    "    start = time.time()\n",
    "    try:\n",
    "        individual_ranking_results = run_dask(\n",
    "            get_ranking_function,\n",
    "            cluster,\n",
    "            client,\n",
    "            model_spec,\n",
    "            data,\n",
    "            fit_results,\n",
    "            parameters_list\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        n_workers = len(client.scheduler_info()['workers'])\n",
    "        print(f\"Elapsed for {n_workers} workers: {elapsed:.2f} seconds\")\n",
    "    finally:\n",
    "        cluster, client = close_client(cluster, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we  have the results from individual ranking calls, we need to combine them and plot! We implemented a utility to allow a user to do this combination quickly and pass the result to plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cabinetry.fit.utils import collect_ranking_results\n",
    "ranking_results = collect_ranking_results(individual_ranking_results)\n",
    "cabinetry.visualize.ranking(\n",
    "    ranking_results, close_figure=True, save_figure=True, figure_folder=\"simple_example/dask_rankings/\", max_pars=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit is too fast right now to see the benefit given the `dask` overhead, so let's add some delay to see the difference between the serial and distirbuted code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delayed_ranking_function(param, model_spec, data, fit_results_serialisable, method=\"auxdata_shift\"):\n",
    "    fit_results_int = cabinetry.model_utils.FitResults(**fit_results_serialisable)\n",
    "    model_int = pyhf.Model(model_spec)\n",
    "    time.sleep(5)\n",
    "    return cabinetry.fit.ranking(\n",
    "        model_int, data,\n",
    "        fit_results=fit_results_int,\n",
    "        impacts_method=method,\n",
    "        parameters_list=[param],\n",
    "        poi_name=\"Signal_norm\"\n",
    "    )\n",
    "\n",
    "test_n_workers = range(1,5,1) if not COFFEA_CASA else [-1]\n",
    "for n_workers in test_n_workers:\n",
    "    cluster, client = get_client(n_workers=n_workers)\n",
    "\n",
    "    start = time.time()\n",
    "    try:\n",
    "        individual_ranking_results = run_dask(\n",
    "            get_delayed_ranking_function,\n",
    "            cluster,\n",
    "            client,\n",
    "            model_spec,\n",
    "            data,\n",
    "            fit_results,\n",
    "            parameters_list[:10],\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        n_workers = len(client.scheduler_info()['workers'])\n",
    "        print(f\"Elapsed for {n_workers} workers: {elapsed:.2f} seconds\")\n",
    "    finally:\n",
    "        cluster, client = close_client(cluster, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_results = cabinetry.fit.utils.collect_ranking_results(individual_ranking_results)\n",
    "cabinetry.visualize.ranking(\n",
    "    ranking_results, close_figure=True, save_figure=True, figure_folder=\"simple_example/dask_delayed_rankings/\", max_pars=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:green;\"> Parallelising fit calls </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can instead choose to let cabinetry handle the parallelisation for them by passing a dask client to the ranking funciton call. Behind the scenes, cabinetry will collect individual calls to the **fit** function, and then submit them to the cluster through the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delayed_paralle_ranking_function(parameters_list, model_spec, data, fit_results_serialisable, method=\"auxdata_shift\"):\n",
    "    time.sleep(5)\n",
    "    return cabinetry.fit.ranking(\n",
    "        model,\n",
    "        data,\n",
    "        fit_results=fit_results,\n",
    "        impacts_method=\"auxdata_shift\",\n",
    "        parameters_list=parameters_list,\n",
    "        client=client\n",
    "    )\n",
    "\n",
    "test_n_workers = [2] if not COFFEA_CASA else [-1]\n",
    "for n_workers in test_n_workers:\n",
    "    cluster, client = get_client(n_workers=n_workers)\n",
    "    start = time.time()\n",
    "    try:\n",
    "        ranking_result_auxdata_shift = delayed_paralle_ranking_function(\n",
    "            parameters_list,\n",
    "            model_spec,\n",
    "            data,\n",
    "            serialize_fit_results(fit_results),\n",
    "            method=\"auxdata_shift\",\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        n_workers = len(client.scheduler_info()['workers'])\n",
    "        print(f\"Elapsed for {n_workers} workers: {elapsed:.2f} seconds\")\n",
    "    finally:\n",
    "        cluster, client = close_client(cluster, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabinetry.visualize.ranking(\n",
    "    ranking_result_auxdata_shift, close_figure=True, save_figure=True, figure_folder=\"simple_example/dask_rankings_by_fit/\", max_pars=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
